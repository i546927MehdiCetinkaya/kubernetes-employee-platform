name: Destroy Infrastructure

on:
  workflow_dispatch:
    inputs:
      confirmation:
        description: 'Type "destroy" to confirm'
        required: true
        type: string

env:
  AWS_REGION: eu-west-1
  TERRAFORM_VERSION: 1.6.0
  KUBECTL_VERSION: v1.28.4

jobs:
  validate-input:
    name: Validate Destruction Request
    runs-on: ubuntu-latest
    steps:
      - name: Check confirmation
        if: github.event.inputs.confirmation != 'destroy'
        run: |
          echo "‚ùå Confirmation failed. You must type 'destroy' to proceed."
          exit 1

      - name: Environment check
        run: |
          echo "üî¥ WARNING: About to destroy infrastructure"
          echo "This action is IRREVERSIBLE!"

  backup:
    name: Create Backup
    needs: [validate-input]
    if: always() && needs.validate-input.result == 'success'
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::920120424621:role/githubrepo
          aws-region: ${{ env.AWS_REGION }}

      - name: Backup DynamoDB tables
        run: |
          echo "Creating DynamoDB backups..."
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Backup employees table
          aws dynamodb create-backup \
            --table-name innovatech-employees \
            --backup-name "pre-destroy-backup-$TIMESTAMP" || true
          
          # Backup workspaces table
          aws dynamodb create-backup \
            --table-name innovatech-employees-workspaces \
            --backup-name "pre-destroy-backup-workspaces-$TIMESTAMP" || true
          
          echo "‚úÖ Backups created"

      - name: Export Terraform state
        run: |
          echo "Note: Terraform state should be backed up if using remote backend"

  destroy-kubernetes:
    name: Destroy Kubernetes Resources
    needs: [validate-input, backup]
    if: |
      always() && 
      needs.validate-input.result == 'success' &&
      (needs.backup.result == 'success' || needs.backup.result == 'skipped')
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::920120424621:role/githubrepo
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
          terraform_wrapper: false

      - name: Get cluster name
        id: cluster
        working-directory: ./terraform
        run: |
          terraform init
          CLUSTER_NAME=$(terraform output -raw eks_cluster_name 2>/dev/null || echo "innovatech-employee-lifecycle")
          echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: ${{ env.KUBECTL_VERSION }}

      - name: Configure kubectl
        continue-on-error: true
        run: |
          aws eks update-kubeconfig \
            --region ${{ env.AWS_REGION }} \
            --name ${{ steps.cluster.outputs.cluster_name }}

      - name: List all resources before deletion
        continue-on-error: true
        run: |
          echo "=== Current Kubernetes Resources ==="
          kubectl get all --all-namespaces || true

      - name: Delete workspaces
        continue-on-error: true
        run: |
          echo "Deleting workspaces..."
          kubectl delete namespace workspaces --timeout=5m || true

      - name: Delete HR Portal
        continue-on-error: true
        run: |
          echo "Deleting HR Portal..."
          kubectl delete -f kubernetes/hr-portal.yaml --timeout=5m || true
          kubectl delete namespace hr-portal --timeout=5m || true

      - name: Delete Network Policies
        continue-on-error: true
        run: |
          echo "Deleting Network Policies..."
          kubectl delete -f kubernetes/network-policies.yaml --timeout=2m || true

      - name: Delete RBAC
        continue-on-error: true
        run: |
          echo "Deleting RBAC..."
          kubectl delete -f kubernetes/rbac.yaml --timeout=2m || true

      - name: Force delete PVCs
        continue-on-error: true
        run: |
          echo "Force deleting PVCs..."
          kubectl delete pvc --all -n workspaces --grace-period=0 --force || true
          kubectl delete pvc --all -n hr-portal --grace-period=0 --force || true

      - name: Verify deletion
        continue-on-error: true
        run: |
          echo "=== Remaining Resources ==="
          kubectl get all --all-namespaces || true

  destroy-infrastructure:
    name: Destroy Terraform Infrastructure
    needs: destroy-kubernetes
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::920120424621:role/githubrepo
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Terraform Plan Destroy
        working-directory: ./terraform
        run: terraform plan -destroy -out=destroy.tfplan

      - name: Terraform Destroy
        working-directory: ./terraform
        run: terraform destroy -auto-approve

      - name: Verify destruction
        run: |
          echo "Verifying resource deletion..."
          
          # Check for remaining resources
          echo "=== Checking VPCs ==="
          aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=*innovatech*" \
            --query 'Vpcs[*].[VpcId,Tags[?Key==`Name`].Value|[0]]' \
            --output table || true
          
          echo "=== Checking EKS Clusters ==="
          aws eks list-clusters \
            --query 'clusters[?contains(@, `innovatech`)]' \
            --output table || true
          
          echo "=== Checking DynamoDB Tables ==="
          aws dynamodb list-tables \
            --query 'TableNames[?contains(@, `innovatech`)]' \
            --output table || true

  cleanup-ecr:
    name: Cleanup ECR Repositories
    needs: destroy-infrastructure
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::920120424621:role/githubrepo
          aws-region: ${{ env.AWS_REGION }}

      - name: Delete ECR repositories
        continue-on-error: true
        run: |
          echo "Deleting ECR repositories..."
          
          REPOS=("hr-portal-backend" "hr-portal-frontend" "employee-workspace")
          
          for repo in "${REPOS[@]}"; do
            echo "Deleting $repo..."
            aws ecr delete-repository \
              --repository-name $repo \
              --force || true
          done

  cleanup-logs:
    name: Cleanup CloudWatch Logs
    needs: destroy-infrastructure
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::920120424621:role/githubrepo
          aws-region: ${{ env.AWS_REGION }}

      - name: Delete CloudWatch log groups
        continue-on-error: true
        run: |
          echo "Deleting CloudWatch log groups..."
          
          # Get all log groups with our prefix
          LOG_GROUPS=$(aws logs describe-log-groups \
            --query 'logGroups[?contains(logGroupName, `innovatech`) || contains(logGroupName, `/aws/eks/innovatech`)].logGroupName' \
            --output text)
          
          for log_group in $LOG_GROUPS; do
            echo "Deleting log group: $log_group"
            aws logs delete-log-group --log-group-name "$log_group" || true
          done

  final-verification:
    name: Final Verification
    needs: [destroy-infrastructure, cleanup-ecr, cleanup-logs]
    if: always()
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::920120424621:role/githubrepo
          aws-region: ${{ env.AWS_REGION }}

      - name: Final resource check
        run: |
          echo "=== FINAL RESOURCE CHECK ==="
          echo ""
          
          echo "Checking for remaining resources..."
          REMAINING=0
          
          # Check VPCs
          VPC_COUNT=$(aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=*innovatech*" \
            --query 'length(Vpcs)' \
            --output text)
          echo "VPCs remaining: $VPC_COUNT"
          REMAINING=$((REMAINING + VPC_COUNT))
          
          # Check EKS
          EKS_COUNT=$(aws eks list-clusters \
            --query 'length(clusters[?contains(@, `innovatech`)])' \
            --output text 2>/dev/null || echo "0")
          echo "EKS clusters remaining: $EKS_COUNT"
          REMAINING=$((REMAINING + EKS_COUNT))
          
          # Check DynamoDB
          DYNAMO_COUNT=$(aws dynamodb list-tables \
            --query 'length(TableNames[?contains(@, `innovatech`)])' \
            --output text 2>/dev/null || echo "0")
          echo "DynamoDB tables remaining: $DYNAMO_COUNT"
          REMAINING=$((REMAINING + DYNAMO_COUNT))
          
          echo ""
          if [ $REMAINING -eq 0 ]; then
            echo "‚úÖ All resources successfully destroyed!"
          else
            echo "‚ö†Ô∏è  Warning: $REMAINING resources may still exist"
            echo "Check AWS Console for any remaining resources"
          fi

  notify:
    name: Send Notification
    needs: [destroy-kubernetes, destroy-infrastructure, cleanup-ecr, cleanup-logs, final-verification]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Destruction Summary
        run: |
          echo "=== Destruction Summary ==="
          echo "Kubernetes: ${{ needs.destroy-kubernetes.result }}"
          echo "Terraform: ${{ needs.destroy-infrastructure.result }}"
          echo "ECR Cleanup: ${{ needs.cleanup-ecr.result }}"
          echo "Logs Cleanup: ${{ needs.cleanup-logs.result }}"
          echo "Verification: ${{ needs.final-verification.result }}"
          echo ""
          
          if [ "${{ needs.final-verification.result }}" == "success" ]; then
            echo "‚úÖ Infrastructure destruction completed"
          else
            echo "‚ö†Ô∏è  Infrastructure destruction completed with warnings"
            echo "Please verify all resources are removed in AWS Console"
          fi
